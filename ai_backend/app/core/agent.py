# app/core/agent.py
import re
import json
import logging
from app.core.llm_client import llm_client 
from app.services.skill_manager import skill_registry, SkillContext

logger = logging.getLogger(__name__)

# --- æœ€ç»ˆä¼˜åŒ–ç‰ˆ System Prompt ---
SYSTEM_PROMPT = """
You are an intelligent AI Agent backend system. 
Your Current Account ID: {account_id}

You have access to the following SKILLS (Tools):
{skill_desc}

### LANGUAGE PROTOCOL (CRITICAL):
1. **Match User Language**: You **MUST** reply in the SAME language as the user's input.
2. **Chinese Priority**: If the user inputs Chinese, your entire output (including reasoning, summaries, and final answer) **MUST be in Chinese**.

### TOOL USAGE STRATEGY (CRITICAL):
1. **PROACTIVE RETRIEVAL (Default Strategy)**: 
   - You have access to a **Knowledge Base** containing the user's private files (Excel, PDF, etc.).
   - **ALWAYS** check if the user's question implies looking up specific data, documents, or history.
   - If the answer is NOT in your general training data (e.g., specific company data, "this file", "uploaded table"), you **MUST** call `knowledge_base_query`.
   - **Do not guess.** If unsure, query the knowledge base first.

2. **"Full Content" / "Read Whole File" (On Demand)**: 
   - Use the `read_full_document` tool **ONLY** if the user **explicitly** asks to "read the whole file", "show full content", "display original text", or "read everything".
   - Do **NOT** use `knowledge_base_query` for full content requests, as it only returns fragments.
   - Do **NOT** use `read_full_document` for general summary or analysis questions (use `knowledge_base_query` instead to save tokens).

### ğŸ›‘ STOP CRITERIA (ANTI-LOOP PROTOCOL):
1. **Limit Attempts**: Do NOT call the same tool with the same arguments more than **2 times**.
2. **Accept Failure**: If `knowledge_base_query` returns "No relevant info found" or similar system notifications, **STOP SEARCHING**. 
   - Do NOT retry with slightly different keywords unless you are very sure.
   - Simply inform the user: "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ (No info found in KB)."
   - Do NOT invent information.
3. **Immediate Answer**: Once you receive a valid <SKILL_RESULT> that answers the question, stop calling tools and output your final answer immediately.

### REASONING PROTOCOL:
- **No Internal Monologue**: Do NOT output <think> tags or internal chain-of-thought (especially for DeepSeek R1).
- **Direct Output**: 
   - If you need a tool: Output the <SKILL_CALL> JSON immediately.
   - If you have the answer: Output the final text immediately.

### FORMAT INSTRUCTIONS:
- Tool Call: <SKILL_CALL>{{"name": "skill_name", "args": {{ "arg1": "value" }} }}</SKILL_CALL>

Current Date: 2025
"""

async def run_agent(messages: list, context: SkillContext):
    """
    Agent ä¸»å¾ªç¯ï¼šæ€è€ƒ -> è°ƒç”¨å·¥å…· -> è·å–ç»“æœ -> å†æ€è€ƒ
    """
    # 1. åŠ¨æ€æ„å»º System Prompt
    skill_desc = skill_registry.get_descriptions_prompt()
    sys_msg = SYSTEM_PROMPT.format(
        account_id=context.account_id,
        skill_desc=skill_desc
    )
    
    # ä¿æŒå†å²è®°å½•ï¼Œå¹¶åœ¨å¤´éƒ¨æ’å…¥ System Prompt
    full_history = [{"role": "system", "content": sys_msg}] + messages
    
    # å…è®¸æœ€å¤§ 10 è½®æ€è€ƒ
    max_turns = 10
    current_turn = 0
    
    while current_turn < max_turns:
        try:
            # è°ƒç”¨ LLM
            content = await llm_client.get_completion(full_history)
            
            # è®°å½• AI çš„å›å¤
            full_history.append({"role": "assistant", "content": content})
            
            # è§£æ <SKILL_CALL>
            match = re.search(r"<SKILL_CALL>(.*?)</SKILL_CALL>", content, re.DOTALL)
            
            if match:
                try:
                    raw_json = match.group(1).strip()
                    call_data = json.loads(raw_json)
                    skill_name = call_data.get("name")
                    skill_args = call_data.get("args", {})
                    
                    logger.info(f"ğŸ”„ Turn {current_turn+1}: Agent calling {skill_name}...")
                    
                    # æ‰§è¡Œ Skill
                    result = await skill_registry.execute(skill_name, skill_args, context)
                    
                    # ç»“æœæˆªæ–­é˜²æ­¢ Context çˆ†ç‚¸ (2000å­—ç¬¦)
                    # å¦‚æœæ˜¯ read_full_document å·²ç»å†…éƒ¨æˆªæ–­äº†ï¼Œè¿™é‡Œä¸»è¦é˜²å…¶ä»–å·¥å…·
                    if len(str(result)) > 5000 and skill_name != 'read_full_document':
                        result = str(result)[:5000] + "...(truncated)"
                    
                    # å›å¡«ç»“æœ
                    result_msg = f"<SKILL_RESULT>{result}</SKILL_RESULT>"
                    full_history.append({"role": "user", "content": "System Notification: " + result_msg})
                    
                    current_turn += 1
                    
                except json.JSONDecodeError:
                    full_history.append({"role": "user", "content": "System Error: Invalid JSON format. Please retry."})
                except Exception as e:
                    full_history.append({"role": "user", "content": f"Tool Error: {str(e)}"})
            else:
                # æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¿”å›æœ€ç»ˆç»“æœ
                return content

        except Exception as e:
            logger.error(f"Agent Loop Error: {e}")
            return "æŠ±æ­‰ï¼Œç³»ç»Ÿå¤„ç†æ—¶å‘ç”Ÿäº†æ„å¤–é”™è¯¯ã€‚"

    # å¦‚æœè¶…å‡ºäº†æœ€å¤§è½®æ•°ï¼Œå¼ºåˆ¶æ€»ç»“
    logger.warning("âš ï¸ Max turns reached. Forcing final answer.")
    force_stop_prompt = [
        {"role": "system", "content": "You have reached the maximum tool usage limit. STOP calling tools now. Please answer the user's question based on the information you have so far."}
    ]
    final_response = await llm_client.get_completion(full_history + force_stop_prompt)
    
    if "<SKILL_CALL>" in final_response:
        return "ä»»åŠ¡è¿‡äºå¤æ‚ï¼Œå·²è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ­¥éª¤ï¼Œæœªèƒ½è·å–å®Œæ•´ç»“æœã€‚"
        
    return final_response